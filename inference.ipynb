{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1011f57-18ee-484a-9c61-e5b97f023ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from peft import PeftModel, PeftConfig\n",
    "from typing import List, Dict, Union\n",
    "import numpy as np\n",
    "\n",
    "class MedicalQAInference:\n",
    "    def __init__(self, model_path: str = \"./final_model\"):\n",
    "        \"\"\"\n",
    "        Initialize the inference pipeline with the fine-tuned model\n",
    "        \n",
    "        Args:\n",
    "            model_path: Path to the saved fine-tuned model\n",
    "        \"\"\"\n",
    "        # Load the configuration\n",
    "        self.peft_config = PeftConfig.from_pretrained(model_path)\n",
    "        \n",
    "        # Load the base tokenizer\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.peft_config.base_model_name_or_path)\n",
    "        \n",
    "        # Load the base model with quantization config\n",
    "        self.base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            self.peft_config.base_model_name_or_path,\n",
    "            num_labels=4,\n",
    "        )\n",
    "        \n",
    "        # Load the PEFT model\n",
    "        self.model = PeftModel.from_pretrained(\n",
    "            self.base_model,\n",
    "            model_path,\n",
    "        )\n",
    "        \n",
    "        # Set model to evaluation mode\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Define option mapping\n",
    "        self.option_mapping = {0: 'A', 1: 'B', 2: 'C', 3: 'D'}\n",
    "\n",
    "    def format_question(self, question: str, options: Dict[str, str]) -> str:\n",
    "        \"\"\"\n",
    "        Format the question and options in the same way as training data\n",
    "        \n",
    "        Args:\n",
    "            question: The medical question\n",
    "            options: Dictionary containing options A, B, C, D\n",
    "            \n",
    "        Returns:\n",
    "            Formatted question string\n",
    "        \"\"\"\n",
    "        return f\"\"\"Question: {question}\n",
    "A) {options['A']}\n",
    "B) {options['B']}\n",
    "C) {options['C']}\n",
    "D) {options['D']}\"\"\"\n",
    "\n",
    "    def predict(self, \n",
    "                question: str, \n",
    "                options: Dict[str, str], \n",
    "                return_probabilities: bool = False\n",
    "               ) -> Union[str, Dict[str, Union[str, List[float]]]]:\n",
    "        \"\"\"\n",
    "        Make a prediction for a single medical question\n",
    "        \n",
    "        Args:\n",
    "            question: The medical question\n",
    "            options: Dictionary containing options A, B, C, D\n",
    "            return_probabilities: Whether to return probability scores\n",
    "            \n",
    "        Returns:\n",
    "            Predicted answer option or dictionary with prediction and probabilities\n",
    "        \"\"\"\n",
    "        # Format the question\n",
    "        formatted_input = self.format_question(question, options)\n",
    "        \n",
    "        # Tokenize\n",
    "        inputs = self.tokenizer(\n",
    "            formatted_input,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            max_length=512\n",
    "        ).to(self.model.device)\n",
    "        \n",
    "        # Get prediction\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            probabilities = torch.softmax(logits, dim=-1)\n",
    "            prediction = torch.argmax(logits, dim=-1)\n",
    "        \n",
    "        # Convert prediction to option letter\n",
    "        predicted_option = self.option_mapping[prediction.item()]\n",
    "        \n",
    "        if return_probabilities:\n",
    "            # Convert probabilities to list and map to options\n",
    "            prob_dict = {\n",
    "                self.option_mapping[i]: prob.item() \n",
    "                for i, prob in enumerate(probabilities[0])\n",
    "            }\n",
    "            return {\n",
    "                'prediction': predicted_option,\n",
    "                'probabilities': prob_dict,\n",
    "                'confidence': prob_dict[predicted_option]\n",
    "            }\n",
    "        \n",
    "        return predicted_option\n",
    "\n",
    "    def batch_predict(self, \n",
    "                     questions: List[Dict[str, Union[str, Dict[str, str]]]]\n",
    "                    ) -> List[Dict[str, Union[str, float]]]:\n",
    "        \"\"\"\n",
    "        Make predictions for a batch of questions\n",
    "        \n",
    "        Args:\n",
    "            questions: List of dictionaries containing questions and options\n",
    "            \n",
    "        Returns:\n",
    "            List of dictionaries with predictions and confidence scores\n",
    "        \"\"\"\n",
    "        formatted_inputs = [\n",
    "            self.format_question(q['question'], q['options']) \n",
    "            for q in questions\n",
    "        ]\n",
    "        \n",
    "        # Tokenize\n",
    "        inputs = self.tokenizer(\n",
    "            formatted_inputs,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=512\n",
    "        ).to(self.model.device)\n",
    "        \n",
    "        # Get predictions\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            probabilities = torch.softmax(logits, dim=-1)\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "        \n",
    "        # Process results\n",
    "        results = []\n",
    "        for i, (pred, probs) in enumerate(zip(predictions, probabilities)):\n",
    "            pred_option = self.option_mapping[pred.item()]\n",
    "            confidence = probs[pred].item()\n",
    "            \n",
    "            results.append({\n",
    "                'question_id': i,\n",
    "                'prediction': pred_option,\n",
    "                'confidence': confidence\n",
    "            })\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed92f1ba-6c23-4b8b-91a7-08fef33dca22",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance Analysis by Difficulty Level:\n",
      "----------------------------------------\n",
      "\n",
      "BASIC Level Questions:\n",
      "Accuracy: 0.0%\n",
      "Average Confidence: 0.316\n",
      "\n",
      "INTERMEDIATE Level Questions:\n",
      "Accuracy: 0.0%\n",
      "Average Confidence: 0.322\n",
      "\n",
      "ADVANCED Level Questions:\n",
      "Accuracy: 0.0%\n",
      "Average Confidence: 0.322\n",
      "\n",
      "Detailed Predictions:\n",
      "--------------------\n",
      "\n",
      "Question 1 (BASIC Level):\n",
      "Q: Which of the following is the most common cause of iron deficiency anemia?\n",
      "Predicted: Option D\n",
      "Correct Answer: Option A\n",
      "Confidence Scores:\n",
      "Option A: 0.2412\n",
      "Option B: 0.2748\n",
      "Option C: 0.1729\n",
      "Option D: 0.3111\n",
      "--------------------------------------------------\n",
      "\n",
      "Question 2 (BASIC Level):\n",
      "Q: The normal range for adult body temperature measured orally is:\n",
      "Predicted: Option D\n",
      "Correct Answer: Option C\n",
      "Confidence Scores:\n",
      "Option A: 0.2342\n",
      "Option B: 0.2649\n",
      "Option C: 0.1806\n",
      "Option D: 0.3203\n",
      "--------------------------------------------------\n",
      "\n",
      "Question 3 (INTERMEDIATE Level):\n",
      "Q: A 45-year-old patient presents with recurrent episodes of facial flushing, diarrhea, and bronchospasm. CT scan reveals a small mass in the terminal ileum. Which of the following is the most likely diagnosis?\n",
      "Predicted: Option D\n",
      "Correct Answer: Option B\n",
      "Confidence Scores:\n",
      "Option A: 0.2382\n",
      "Option B: 0.2656\n",
      "Option C: 0.1739\n",
      "Option D: 0.3223\n",
      "--------------------------------------------------\n",
      "\n",
      "Question 4 (INTERMEDIATE Level):\n",
      "Q: In the treatment of acute bacterial meningitis, which of the following factors most strongly influences the choice of empiric antibiotic therapy?\n",
      "Predicted: Option D\n",
      "Correct Answer: Option A\n",
      "Confidence Scores:\n",
      "Option A: 0.2342\n",
      "Option B: 0.2633\n",
      "Option C: 0.1808\n",
      "Option D: 0.3218\n",
      "--------------------------------------------------\n",
      "\n",
      "Question 5 (ADVANCED Level):\n",
      "Q: A 28-year-old woman with systemic lupus erythematosus develops sudden onset of left-sided weakness and slurred speech. Laboratory studies reveal a prolonged PTT, positive lupus anticoagulant, and anti-cardiolipin antibodies. Brain MRI shows multiple small cortical infarcts. Which of the following is the most appropriate initial treatment?\n",
      "Predicted: Option D\n",
      "Correct Answer: Option B\n",
      "Confidence Scores:\n",
      "Option A: 0.2342\n",
      "Option B: 0.2610\n",
      "Option C: 0.1823\n",
      "Option D: 0.3225\n",
      "--------------------------------------------------\n",
      "\n",
      "Question 6 (ADVANCED Level):\n",
      "Q: A 62-year-old male with chronic hepatitis B develops hepatorenal syndrome. Despite treatment with vasoconstrictors and albumin, his renal function continues to worsen. Laboratory studies show: Creatinine 4.2 mg/dL, INR 2.1, Total bilirubin 5.8 mg/dL, Albumin 2.8 g/dL. Calculate his MELD score and determine the most appropriate next step in management.\n",
      "Predicted: Option D\n",
      "Correct Answer: Option B\n",
      "Confidence Scores:\n",
      "Option A: 0.2331\n",
      "Option B: 0.2626\n",
      "Option C: 0.1831\n",
      "Option D: 0.3213\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Create a diverse set of test questions across difficulty levels\n",
    "batch_questions = [\n",
    "    # Basic Questions\n",
    "    {\n",
    "        'question': \"Which of the following is the most common cause of iron deficiency anemia?\",\n",
    "        'options': {\n",
    "            'A': 'Chronic blood loss',\n",
    "            'B': 'Decreased iron absorption',\n",
    "            'C': 'Increased iron demand',\n",
    "            'D': 'Dietary deficiency'\n",
    "        },\n",
    "        'difficulty': 'basic',\n",
    "        'correct_answer': 'A'  # For validation\n",
    "    },\n",
    "    {\n",
    "        'question': \"The normal range for adult body temperature measured orally is:\",\n",
    "        'options': {\n",
    "            'A': '35.0-36.0°C',\n",
    "            'B': '36.0-37.0°C',\n",
    "            'C': '36.5-37.5°C',\n",
    "            'D': '37.5-38.5°C'\n",
    "        },\n",
    "        'difficulty': 'basic',\n",
    "        'correct_answer': 'C'  # For validation\n",
    "    },\n",
    "\n",
    "    # Intermediate Questions\n",
    "    {\n",
    "        'question': \"A 45-year-old patient presents with recurrent episodes of facial flushing, diarrhea, and bronchospasm. CT scan reveals a small mass in the terminal ileum. Which of the following is the most likely diagnosis?\",\n",
    "        'options': {\n",
    "            'A': 'Gastrinoma',\n",
    "            'B': 'Carcinoid syndrome',\n",
    "            'C': 'VIPoma',\n",
    "            'D': 'Pheochromocytoma'\n",
    "        },\n",
    "        'difficulty': 'intermediate',\n",
    "        'correct_answer': 'B'  # For validation\n",
    "    },\n",
    "    \n",
    "    {\n",
    "        'question': \"In the treatment of acute bacterial meningitis, which of the following factors most strongly influences the choice of empiric antibiotic therapy?\",\n",
    "        'options': {\n",
    "            'A': \"Patient's age\",\n",
    "            'B': 'Recent antibiotic use',\n",
    "            'C': 'Duration of symptoms',\n",
    "            'D': 'Presence of skin rash'\n",
    "        },\n",
    "        'difficulty': 'intermediate',\n",
    "        'correct_answer': 'A'  # For validation\n",
    "    },\n",
    "\n",
    "    # Advanced Questions\n",
    "    {\n",
    "        'question': \"A 28-year-old woman with systemic lupus erythematosus develops sudden onset of left-sided weakness and slurred speech. Laboratory studies reveal a prolonged PTT, positive lupus anticoagulant, and anti-cardiolipin antibodies. Brain MRI shows multiple small cortical infarcts. Which of the following is the most appropriate initial treatment?\",\n",
    "        'options': {\n",
    "            'A': 'Aspirin',\n",
    "            'B': 'Unfractionated heparin',\n",
    "            'C': 'Cyclophosphamide',\n",
    "            'D': 'Tissue plasminogen activator'\n",
    "        },\n",
    "        'difficulty': 'advanced',\n",
    "        'correct_answer': 'B'  # For validation\n",
    "    },\n",
    "    {\n",
    "        'question': \"A 62-year-old male with chronic hepatitis B develops hepatorenal syndrome. Despite treatment with vasoconstrictors and albumin, his renal function continues to worsen. Laboratory studies show: Creatinine 4.2 mg/dL, INR 2.1, Total bilirubin 5.8 mg/dL, Albumin 2.8 g/dL. Calculate his MELD score and determine the most appropriate next step in management.\",\n",
    "        'options': {\n",
    "            'A': 'MELD 25; Continue medical management',\n",
    "            'B': 'MELD 28; Evaluate for liver transplantation',\n",
    "            'C': 'MELD 32; Initiate hemodialysis',\n",
    "            'D': 'MELD 35; Palliative care consultation'\n",
    "        },\n",
    "        'difficulty': 'advanced',\n",
    "        'correct_answer': 'B'  # For validation\n",
    "    }\n",
    "]\n",
    "\n",
    "# Function to evaluate model performance across difficulty levels\n",
    "def evaluate_by_difficulty(inference_model, questions):\n",
    "    results = inference_model.batch_predict(questions)\n",
    "    \n",
    "    # Group results by difficulty\n",
    "    performance = {\n",
    "        'basic': {'correct': 0, 'total': 0, 'confidence': []},\n",
    "        'intermediate': {'correct': 0, 'total': 0, 'confidence': []},\n",
    "        'advanced': {'correct': 0, 'total': 0, 'confidence': []}\n",
    "    }\n",
    "    \n",
    "    for i, result in enumerate(results):\n",
    "        difficulty = questions[i]['difficulty']\n",
    "        correct_answer = questions[i]['correct_answer']\n",
    "        \n",
    "        # Update statistics\n",
    "        performance[difficulty]['total'] += 1\n",
    "        performance[difficulty]['confidence'].append(result['confidence'])\n",
    "        if result['prediction'] == correct_answer:\n",
    "            performance[difficulty]['correct'] += 1\n",
    "    \n",
    "    # Calculate and display statistics\n",
    "    print(\"\\nPerformance Analysis by Difficulty Level:\")\n",
    "    print(\"----------------------------------------\")\n",
    "    for difficulty in ['basic', 'intermediate', 'advanced']:\n",
    "        stats = performance[difficulty]\n",
    "        accuracy = (stats['correct'] / stats['total']) * 100 if stats['total'] > 0 else 0\n",
    "        avg_confidence = sum(stats['confidence']) / len(stats['confidence']) if stats['confidence'] else 0\n",
    "        \n",
    "        print(f\"\\n{difficulty.upper()} Level Questions:\")\n",
    "        print(f\"Accuracy: {accuracy:.1f}%\")\n",
    "        print(f\"Average Confidence: {avg_confidence:.3f}\")\n",
    "\n",
    "    return performance\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize inference model\n",
    "    inference = MedicalQAInference(\"./final_model\")\n",
    "    \n",
    "    # Run evaluation\n",
    "    performance_metrics = evaluate_by_difficulty(inference, batch_questions)\n",
    "    \n",
    "    # Print detailed predictions\n",
    "    print(\"\\nDetailed Predictions:\")\n",
    "    print(\"--------------------\")\n",
    "    for i, question in enumerate(batch_questions):\n",
    "        result = inference.predict(\n",
    "            question['question'], \n",
    "            question['options'], \n",
    "            return_probabilities=True\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nQuestion {i+1} ({question['difficulty'].upper()} Level):\")\n",
    "        print(f\"Q: {question['question']}\")\n",
    "        print(f\"Predicted: Option {result['prediction']}\")\n",
    "        print(f\"Correct Answer: Option {question['correct_answer']}\")\n",
    "        print(\"Confidence Scores:\")\n",
    "        for option, prob in result['probabilities'].items():\n",
    "            print(f\"Option {option}: {prob:.4f}\")\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b739bcb-8d0a-4b5c-8192-d11d3fdd895e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "def main():\n",
    "    # Initialize inference pipeline\n",
    "    inference = MedicalQAInference(\"./final_model\")\n",
    "    \n",
    "    # Single question example\n",
    "    question = \"Chronic urethral obstruction due to benign prismatic hyperplasia can lead to the following change in kidney parenchyma\"\n",
    "    options = {\n",
    "        'A': 'Hyperplasia',\n",
    "        'B': 'Hyperophy',\n",
    "        'C': 'Atrophy',\n",
    "        'D': 'Dyplasia'\n",
    "    }\n",
    "    \n",
    "    # Get prediction with probabilities\n",
    "    result = inference.predict(question, options, return_probabilities=True)\n",
    "    print(\"\\nSingle Question Prediction:\")\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Predicted Answer: Option {result['prediction']}\")\n",
    "    print(\"Confidence Scores:\")\n",
    "    for option, prob in result['probabilities'].items():\n",
    "        print(f\"Option {option}: {prob:.4f}\")\n",
    "    \n",
    "    # Batch prediction example\n",
    "    batch_questions = [\n",
    "        {\n",
    "            'question': question,\n",
    "            'options': options\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            'question': \"Another medical question...\",\n",
    "            'options': {\n",
    "                'A': 'Option A',\n",
    "                'B': 'Option B',\n",
    "                'C': 'Option C',\n",
    "                'D': 'Option D'\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    batch_results = inference.batch_predict(batch_questions)\n",
    "    print(\"\\nBatch Prediction Results:\")\n",
    "    for result in batch_results:\n",
    "        print(f\"Question {result['question_id']}: Option {result['prediction']} (Confidence: {result['confidence']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12a52aa8-1a22-4334-b710-f09deae0e84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Single Question Prediction:\n",
      "Question: Chronic urethral obstruction due to benign prismatic hyperplasia can lead to the following change in kidney parenchyma\n",
      "Predicted Answer: Option A\n",
      "Confidence Scores:\n",
      "Option A: 0.2870\n",
      "Option B: 0.2112\n",
      "Option C: 0.2386\n",
      "Option D: 0.2632\n",
      "\n",
      "Batch Prediction Results:\n",
      "Question 0: Option A (Confidence: 0.2870)\n",
      "Question 1: Option A (Confidence: 0.2901)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198cc35a-612d-451c-9061-2ec46cda5819",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
